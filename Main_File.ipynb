{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f942ea9f-9eb0-42fd-b797-5fd7491b5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'merged_dataset.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def9f857-fad1-476b-9542-9c2e120048ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  new_sentiment\n",
      "0  when modi promised “minimum government maximum...           -1.0\n",
      "1  talk all the nonsense and continue all the dra...            0.0\n",
      "2  what did just say vote for modi  welcome bjp t...            1.0\n",
      "3  asking his supporters prefix chowkidar their n...            1.0\n",
      "4  answer who among these the most powerful world...            1.0\n"
     ]
    }
   ],
   "source": [
    "print(df.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d5bfcf-edcf-4f3b-ae85-46240b94a481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     tweet  new_sentiment\n",
      "3305353  HealthStream, Inc. $HSTM Short Interest Down 1...            1.0\n",
      "3305354  $SPY $QQQ $IWM $AAPL &lt;smh&gt;  Gonna go gre...            1.0\n",
      "3305355  RT @hyumialert: [ $SPY $QQQ $IWM $SPX $NDX $RU...            1.0\n",
      "3305356  #UNILEVER https://t.co/ZTIcvYqTx7 Pot. interme...            1.0\n",
      "3305357  $566.85 Million in Sales Expected for Nabors I...            1.0\n",
      "3305358  @TheDomino @AndrewFactor @CNBC Crazy, right?!?...            1.0\n",
      "3305359  #Stocks making the biggest moves in the premar...            1.0\n",
      "3305360  RT @leadlagreport: Buying The Dip Is NOT An In...            1.0\n",
      "3305361  @TurnerNovak Only difference is $FB was at an ...            1.0\n",
      "3305362  1st Source Co. $SRCE Short Interest Update htt...            1.0\n",
      "3305363  All these puts printing \\n\\n$spy $nugt $jpm $c...            1.0\n",
      "3305364  RT @CarterBWorth: The mkt's been at current le...            1.0\n",
      "3305365  RT @MacroCharts: Amazon $AMZN.\\n\\nFOMO traders...            1.0\n",
      "3305366  RT @MarketRealist: Facebook Ad Boycott: Zucker...            1.0\n",
      "3305367  If you are new to stock markets and want to in...            1.0\n",
      "3305368  Brokers Offer Predictions for National-Oilwell...            1.0\n",
      "3305369  RT @MarkNewtonCMT: $IHI Ishares Medical Dvcs E...            1.0\n",
      "3305370  $CODX latest news from FDA is a game changer!\\...            1.0\n",
      "3305371  We're still looking for someone else who can b...            1.0\n",
      "3305372  Zacks: Analysts Anticipate Ulta Beauty Inc $UL...            1.0\n",
      "3305373  RT @HedgehogTrader: HHT's Venture/Microcap Sto...            1.0\n",
      "3305374  $FB This didn’t get much playtime this week. I...            1.0\n",
      "3305375  @willschoebs Connecting two of your excellent ...            1.0\n",
      "3305376  Your ordinary person would focus on buying pur...            1.0\n",
      "3305377  RT @smtraderCA: \"Is A Big Moving Coming?\" for ...            1.0\n",
      "3305378  With ad revenues falling, what’s the impact on...            1.0\n",
      "3305379  RT @KelvinSCWong: Well another point to add to...            1.0\n",
      "3305380  $ITOX working on a contract with a fortune 500...            1.0\n",
      "3305381  $DIS it could break the 120 pin, then 125&gt; ...            1.0\n",
      "3305382  Amedisys Inc $AMED COO Christopher Gerard Sell...            1.0\n"
     ]
    }
   ],
   "source": [
    "print(df.tail(30)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca26c2c-d037-40f4-84c8-8d4f4aef9ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3305383 entries, 0 to 3305382\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   tweet          object \n",
      " 1   new_sentiment  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 50.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b47e924-d44b-4a41-a6a0-96f176c0179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_sentiment\n",
      " 0.0    1616824\n",
      "-1.0    1605577\n",
      " 1.0      82975\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['new_sentiment'].value_counts())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0879691e-3f56-458b-989f-a8df431992b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet            4\n",
       "new_sentiment    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ddb3147-d48d-4fb0-ac62-5b9be1de6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna( inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87010217-4410-4469-b5fb-cd1c6541c76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet            0\n",
       "new_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1649e1-ed29-4dc7-b0c4-86edaba9a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgadg\\AppData\\Local\\Temp\\ipykernel_25312\\3987304729.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=df['new_sentiment'], palette=\"muted\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHDCAYAAAA3LZJHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALXVJREFUeJzt3Q+UVVW9B/Aff+SPGZiiIISi+f8fmCSi9dTESA2f+XqamhApL1PL5JVKKoiaPEsQS5SnhWj+AXUpWfogRUlNWgZKZYVGYhDKvwwGUMFg3tpnrZkYmMGZkZk7m/l81joM59xzzt33ztyZ7933t/dpUV5eXh4AAJChlqVuAAAA1JcwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAtk7eqrr44WLVo0yn0de+yxxVJhxowZxX0/9NBDjXL/X/7yl6NHjx7RlK1evTrOO++86NKlS/HcfPOb36zzOdJx6fsKUBvCLNBkTJw4sQgyFUu7du2ia9eu0b9///jBD34Qq1at2ir388YbbxRhac6cOdHUNOW21cb1119ffB+/9rWvxU9+8pM455xzGu2+//jHPxbP3euvv95o9wmUXutSNwBgU9dcc03sueee8d5778XixYuLHtDUwzdmzJh49NFH49BDD63c98orr4zLL7+8zoFx5MiRRS9nr169an3cL37xi2hoW2rbHXfcERs2bIim7KmnnoojjzwyRowY0ej3ncJseu5S73lT78EGth5hFmhyTjzxxOjdu3fl+rBhw4qQ9LnPfS5OOeWU+NOf/hTt27cvbmvdunWxNKS33347tt9++2jTpk2U0nbbbRdN3dKlS+PAAw8sdTOAZkSZAZCFT3/603HVVVfFX//617jnnnu2WDP7xBNPxCc/+cnYcccdY4cddoj99tsvvvOd7xS3pV7eT3ziE8X/Bw8eXFnSkD4aT1Kv3sEHHxyzZ8+Of/u3fytCbMWxm9bMVli/fn2xT6oT/dCHPlQE7oULF1bZJ/UUpprXTW18zvdrW3U1s2vWrIn//u//ju7du0fbtm2Lx3rjjTdGeXl5lf3SeS666KKYMmVK8fjSvgcddFBMnTq11iH13HPPjc6dOxflHz179oy77rprs/rh+fPnx2OPPVbZ9i195L927dq45JJLYpdddokPf/jDxfP2t7/9bbP90vf8ggsuKB5behOz8847x3/+539WOXd6jtK25Ljjjqu8/9Su5Kc//WmcfPLJRdlKeuwf+9jH4tprry2+d0De9MwC2Uj1lyk0po/7hwwZUu0+f/jDH4oe3FSKkMoVUnCZN29e/OpXvypuP+CAA4rtw4cPj//6r/+KT33qU8X2o446qvIcf//734ve4S9+8YvxpS99qQhwW/Ld7363CE6XXXZZEfrGjh0b/fr1K+peK3qQa6M2bdtYCqwpAD799NNF0ExlCdOmTYtvf/vbsWjRorjpppuq7P/cc8/Fww8/XATDFB5THfJ//Md/xIIFC4qAWJN33nmnCNzpeUyBOJWAPPjgg0W4XrFiRVx88cVF21ONbAqnH/3oR4uAnaSgWpM0UCy9MTnrrLOKx5h631Pg3NRvfvObeP7554vvRzp3CrG33XZb0aZUWpDecKQ3Ht/4xjeKx5R+RlJ7Kp7TirCb3tgMHTq0+JruKz3PZWVl8f3vf79W3x+giSoHaCLuvPPO1J1Y/pvf/KbGfTp27Fh+2GGHVa6PGDGiOKbCTTfdVKwvW7asxnOk86d90v1t6phjjiluGz9+fLW3paXC008/XezbrVu38rKyssrtDzzwQLH95ptvrty2xx57lA8aNOh9z7mltqXj03kqTJkypdj3uuuuq7LfF77whfIWLVqUz5s3r3Jb2q9NmzZVtv32t78ttv/whz8s35KxY8cW+91zzz2V29atW1fet2/f8h122KHKY0/tO/nkk8vfz5w5c4pzXnDBBVW2n3XWWcX29H2t8Pbbb292/MyZM4v97r777sptDz74YLEtfV82Vd05vvrVr5Zvv/325e++++77thdoupQZAFlJvWpbmtUglRZUfKxc38FSqTc3fcxfWwMHDix6Oit84QtfiN122y0ef/zxaEjp/K1atSp6JDeWekVTfv2///u/KttTb3H6eL1C6r3u0KFDvPbaa+97P6mE4swzz6xSv5vuN03F9ctf/rJebU82bXt1U3lt3LudBgWmnvO99967+F6/+OKLtbq/jc+Rfn6WL19e9Hyneui5c+fWuf1A09Gsw+wzzzwTAwYMKGqo0keEqZasrtIfjFSftu+++xZ/ALt161Z85Ag0jBSeNg6OmzrjjDPi6KOPLj7CTuUB6aPpBx54oE7BNr2O6zLYa5999qmynn6fpLDV0FNEpVrS9Ptr0+ej4qP1dPvGdt99983O8ZGPfCT+8Y9/vO/9pMfYsmXLWt1PbduezrdxuE5SXWx1ZQ6pJKCiLrhTp05F+UIqcVi5cmWt7i+Vn3z+85+Pjh07FgE+HZ9KSJLangNompp1zWwaOJEGMXzlK1+J0047rV7nSLViqX4vBdpDDjkk3nrrrWIBtr40OCgFjxQUt9QDl96opjrSNBApDXCaPHlyMYAsvVZTT+b7qUuda23VdGGHNACpNm3aGmq6n00HizU1X//61+POO+8sem379u1bBNL0fKY3KrV5k5JC7zHHHFOE2FSTnAJ0GsSWenVTnXNTn+4M2LJmHWbTAI+0bGmk7RVXXBH3339/8cswjQC+4YYbKkcep+mB0iCEl19+ubI3IQ2MABpGGmCUpIsobEnq8Tv++OOLJc1NmybyT6/lFHDTR+1b+4phf/7znzcLh2mw1Mbz4aYe0PR7pLoeyr322qtyvS5t22OPPeLJJ58sPjbfuHe24mPzdPvWkM7zu9/9rgh9G/fOfpD7Scek8/3lL3+p0hv7yiuvbLZvusLaoEGDYvTo0ZXb3n333c2ez5qeuzSjQSpNSIPf0kCxCmnmBSB/zbrM4P2kUbszZ86MSZMmFb/I07Qvn/3sZyv/cP3sZz8r/gj9/Oc/L0JsmjInfbSpZxa2vjT6PE2llF5rZ599do37Vff6q7j4QHqDmqTps5LqwmV93H333VXqeFP4evPNN6u8WU69gb/+9a9j3bp1ldvS745Np/CqS9tOOumkomf3lltuqbI9zWKQgt2W3qzXRbqfdPGK1MNd4Z///Gf88Ic/LGqYU69nXVW0Lc0+sLE0E0R1Pcqb9h6n+950Wq2anruKHumNz5G+D7feemud2w00Pc26Z3ZL0lQ16WOt9DXVpCXf+ta3io8s0/bU05MGTaRelTRFTfpjln6xpmlp0uCP9IcXqJ80cCn1+qXAtGTJkuL1lOaOTb156Qpg6SPimqSPkVOZQZriKe2fpspKoSVN6ZTmnq0Ilmnw0Pjx44sezRSC+vTpU+9PVnbaaafi3GnQWGpvCmSpFGLj6cPSG90UctMb4tNPP73okUzTUm1aM1qXtqWa/zSnaup1TvW5qWwqlVKkwW/pI/lNz11faZqw//3f/y2m4krz76Y37umxpOnO0mPdUg1zTdIbjDSgLH1vUulImppr+vTpRY/2ptJUa6lXPpUXpAsypE6G1CO96XRi6ZwpuKZP0NI5U31tKi9J504946l3Nw04S0E/na+pl1cAtVTq6RSaivRUPPLII5XrP//5z4ttH/rQh6osrVu3Lj/99NOLfYYMGVLs88orr1QeN3v27GLb3LlzS/I4YFuYmqtiSVNJdenSpfyEE04oprnaeAqomqbmmj59evm///u/l3ft2rU4Pn0988wzy1999dUqx/30pz8tP/DAA4vX9MZTYaVpsg466KBq21fT1Fz3339/+bBhw8p33XXX8vbt2xdTU/31r3/d7PjRo0cX03i1bdu2/Oijjy6fNWvWZufcUts2nZorWbVqVfkll1xSPM7tttuufJ999in//ve/X75hw4Yq+6XzXHjhhZu1qaYpwza1ZMmS8sGDB5d36tSpeF4POeSQaqcPq+3UXMk777xT/o1vfKN85513Ln6/DhgwoHzhwoWbTc31j3/8o/K+01Rg/fv3L37HVtf2O+64o3yvvfYqb9WqVZVpun71q1+VH3nkkcX3Jz1Xl156afm0adNqnMoLyEeL9E9tg++2LL1Tf+SRR+LUU08t1tPHaemjzDQCdtNBE+ljtTRNTbr2eOqhTVPFbDzqNk3gnXpHTjjhhEZ/HAAAzYkygxocdthhRdlA+oiy4io8m0rT/6SPQdPHhRUf57366qtbdeAFAAA1a9Y9s2m+yor6rBRe06jnVH+W6t/SfIxpDsJUE5ZG0Kbbly1bVtR0pRHKqR4vjcRN11FPPbWpbiytX3jhhcX0L6lnFgCAhtWsw2yariWF102lQQLpOt6pfOC6664rBnel65ynibqPPPLIGDlyZDGnbPLGG28UcyCm8JoGaqQRuin8pkAMAEDDatZhFgCAvJlnFgCAbAmzAABkq9nNZpAGaaU61zTJ99a+pCUAAB9cqoJNV1ZMF67a+DLa1Wl2YTYF2e7du5e6GQAAvI90ye90BcctaXZhtuKyi+nJSVNoAQDQtJSVlRWdj7W5XHazC7MVpQUpyAqzAABNV21KQg0AAwAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbJU0zD7zzDMxYMCA6Nq1a7Ro0SKmTJnyvsesXbs2rrjiithjjz2ibdu20aNHj5gwYUKjtBcAgKaldSnvfM2aNdGzZ8/4yle+Eqeddlqtjjn99NNjyZIl8eMf/zj23nvvePPNN2PDhg0N3lagYbx645dL3QSoYt9vTSx1E4BcwuyJJ55YLLU1derU+OUvfxmvvfZa7LTTTsW21DMLAEDzVNIwW1ePPvpo9O7dO773ve/FT37yk/jQhz4Up5xySlx77bXRvn37GssS0lKhrKysQdp21vAZDXJeqK/7rjm21E0AgAaXVZhNPbLPPfdctGvXLh555JFYvnx5XHDBBfH3v/897rzzzmqPGTVqVIwcObLR2woAQMPLajaDVBubBorde++9ccQRR8RJJ50UY8aMibvuuiveeeedao8ZNmxYrFy5snJZuHBho7cbAICGkVXP7G677RbdunWLjh07Vm474IADory8PP72t7/FPvvss9kxacaDtAAAsO3Jqmf26KOPjjfeeCNWr15due3VV1+Nli1bxkc/+tGStg0AgGYWZlMonTNnTrEk8+fPL/6/YMGCyhKBgQMHVu5/1llnxc477xyDBw+OP/7xj8U8td/+9reLqb1qGgAGAMC2q6RhdtasWXHYYYcVSzJ06NDi/8OHDy/W0xyyFcE22WGHHeKJJ56IFStWFLManH322cVFF37wgx+U7DEAANBMa2aPPfbYot61JhMnbj5x9f77718EWgAAyKpmFgAANibMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkK2ShtlnnnkmBgwYEF27do0WLVrElClTan3sr371q2jdunX06tWrQdsIAEDTVdIwu2bNmujZs2eMGzeuTsetWLEiBg4cGMcff3yDtQ0AgKavdSnv/MQTTyyWujr//PPjrLPOilatWtWpNxcAgG1LdjWzd955Z7z22msxYsSIUjcFAIDm3DNbV3/+85/j8ssvj2effbaol62NtWvXFkuFsrKyBmwhAACNKZue2fXr1xelBSNHjox999231seNGjUqOnbsWLl07969QdsJAEDjySbMrlq1KmbNmhUXXXRR0SublmuuuSZ++9vfFv9/6qmnqj1u2LBhsXLlyspl4cKFjd52AACaeZlBhw4d4ve//32VbbfeemsRYh966KHYc889qz2ubdu2xQIAwLanpGF29erVMW/evMr1+fPnx5w5c2KnnXaK3XffvehVXbRoUdx9993RsmXLOPjgg6scv+uuu0a7du022w4AQPNQ0jCbygaOO+64yvWhQ4cWXwcNGhQTJ06MN998MxYsWFDCFgIA0JSVNMwee+yxUV5eXuPtKdBuydVXX10sAAA0T9kMAAMAgE0JswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFslDbPPPPNMDBgwILp27RotWrSIKVOmbHH/hx9+OE444YTYZZddokOHDtG3b9+YNm1ao7UXAICmpaRhds2aNdGzZ88YN25crcNvCrOPP/54zJ49O4477rgiDL/00ksN3lYAAJqe1qW88xNPPLFYamvs2LFV1q+//vr46U9/Gj/72c/isMMOa4AWAgDQlJU0zH5QGzZsiFWrVsVOO+1U4z5r164tlgplZWWN1DoAABpa1gPAbrzxxli9enWcfvrpNe4zatSo6NixY+XSvXv3Rm0jAAANJ9swe99998XIkSPjgQceiF133bXG/YYNGxYrV66sXBYuXNio7QQAoOFkWWYwadKkOO+88+LBBx+Mfv36bXHftm3bFgsAANue7Hpm77///hg8eHDx9eSTTy51cwAAaK49s6nedd68eZXr8+fPjzlz5hQDunbfffeiRGDRokVx9913V5YWDBo0KG6++ebo06dPLF68uNjevn37oh4WAIDmpaQ9s7NmzSqm1KqYVmvo0KHF/4cPH16sv/nmm7FgwYLK/W+//fb45z//GRdeeGHstttulcvFF19csscAAEAz7Zk99thjo7y8vMbbJ06cWGV9xowZjdAqAABykV3NLAAAVBBmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyFZJw+wzzzwTAwYMiK5du0aLFi1iypQp73vMjBkz4uMf/3i0bds29t5775g4cWKjtBUAgKanpGF2zZo10bNnzxg3blyt9p8/f36cfPLJcdxxx8WcOXPim9/8Zpx33nkxbdq0Bm8rAABNT+tS3vmJJ55YLLU1fvz42HPPPWP06NHF+gEHHBDPPfdc3HTTTdG/f/8GbCkAAE1RVjWzM2fOjH79+lXZlkJs2l6TtWvXRllZWZUFAIBtQ1ZhdvHixdG5c+cq29J6CqjvvPNOtceMGjUqOnbsWLl07969kVoLAEBDyyrM1sewYcNi5cqVlcvChQtL3SQAALaFmtm66tKlSyxZsqTKtrTeoUOHaN++fbXHpFkP0gIAwLYnq57Zvn37xvTp06tse+KJJ4rtAAA0PyUNs6tXry6m2EpLxdRb6f8LFiyoLBEYOHBg5f7nn39+vPbaa3HppZfG3Llz49Zbb40HHnggLrnkkpI9BgAAmmmYnTVrVhx22GHFkgwdOrT4//Dhw4v1N998szLYJmlarscee6zojU3z06Ypun70ox+ZlgsAoJkqac3sscceG+Xl5TXeXt3VvdIxL730UgO3DACAHGRVMwsAABsTZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADNK8zutdde8fe//32z7StWrChuAwCAJhtmX3/99Vi/fv1m29euXRuLFi3aGu0CAID31Trq4NFHH638/7Rp06Jjx46V6yncTp8+PXr06FGXUwIAQOOE2VNPPbX42qJFixg0aFCV27bbbrsiyI4ePbr+rQEAgIYKsxs2bCi+7rnnnvGb3/wmOnXqVJfDAQCgdGG2wvz587duKwAAoLHCbJLqY9OydOnSyh7bChMmTKjvaQEAoGHD7MiRI+Oaa66J3r17x2677VbU0AIAQBZhdvz48TFx4sQ455xztn6LAACgIeeZXbduXRx11FH1ORQAAEobZs8777y47777tl4rAACgscoM3n333bj99tvjySefjEMPPbSYY3ZjY8aMqc9pAQCg4cPs7373u+jVq1fx/5dffrnKbQaDAQDQpMPs008/vfVbAgAAjVEzCwAA2fbMHnfccVssJ3jqqac+SJsAAKDhwmxFvWyF9957L+bMmVPUzw4aNKg+pwQAgMYJszfddFO126+++upYvXp1fU4JAAClrZn90pe+FBMmTNiapwQAgMYJszNnzox27dptzVMCAMDWLTM47bTTqqyXl5fHm2++GbNmzYqrrrqqPqcEAIDGCbMdO3asst6yZcvYb7/94pprronPfOYz9TklAAA0Tpi9884763MYAACUPsxWmD17dvzpT38q/n/QQQfFYYcdtrXaBQAADRNmly5dGl/84hdjxowZseOOOxbbVqxYUVxMYdKkSbHLLrvU57QAANDwsxl8/etfj1WrVsUf/vCHeOutt4olXTChrKwsvvGNb9T5fOPGjYsePXoUMyH06dMnXnjhhS3uP3bs2KJGt3379tG9e/e45JJL4t13363PQwEAoLn1zE6dOjWefPLJOOCAAyq3HXjggUUoresAsMmTJ8fQoUNj/PjxRZBNQbV///7xyiuvxK677rrZ/vfdd19cfvnlxXy2Rx11VLz66qvx5S9/ubi87pgxY+rzcAAAaE49sxs2bIjttttus+1pW7qtLlIAHTJkSAwePLgIxCnUbr/99jVefOH555+Po48+Os4666yiNzeF5zPPPPN9e3MBANj21CvMfvrTn46LL7443njjjcptixYtKj7uP/7442t9nnXr1hWDyPr16/evBrVsWaynCzBUJ/XGpmMqwutrr70Wjz/+eJx00kn1eSgAADS3MoNbbrklTjnllKJnNNWsJgsXLoyDDz447rnnnlqfZ/ny5bF+/fro3Llzle1pfe7cudUek3pk03Gf/OQni4s1/POf/4zzzz8/vvOd71S7/9q1a4ulQqrrBQCgGYfZFGBffPHFom62InSm+tmNe1gbSppB4frrr49bb721qLGdN29e0Ut87bXXVnv1sVGjRsXIkSMbvF0AADTxMoOnnnqqqGtNvZtpwNUJJ5xQzGyQlk984hPFXLPPPvtsrc/XqVOnaNWqVSxZsqTK9rTepUuXao9JgfWcc86J8847Lw455JD4/Oc/X4TbFFqrq9cdNmxYrFy5snJJPcgAADTDMJtmGkiDtTp06FDtJW6/+tWv1mlGgTZt2sThhx8e06dPr9yWAmla79u3b7XHvP3220Vd7cZSIE5S2cGm2rZtW7R34wUAgGYYZn/729/GZz/72RpvTzMLpMFZdZGm5brjjjvirrvuKq4m9rWvfS3WrFlTzG6QDBw4sOhdrTBgwIC47bbbioszzJ8/P5544omitzZtrwi1AAA0D3WqmU0f/1c3JVflyVq3jmXLltWpAWeccUZxzPDhw2Px4sXRq1evYh7bikFhCxYsqNITe+WVVxYlDulrmkEhXW0sBdnvfve7dbpfAACaWZjt1q1bcaWvvffeu9rbf/e738Vuu+1W50ZcdNFFxVLTgK9NA/OIESOKBQCA5q1OZQZpLtf0kX51l4595513ioD5uc99bmu2DwAAtk7PbPpo/+GHH45999236Endb7/9iu1peq50Kds0Z+wVV1xRl1MCAEDjhNlUx5ouJ5sGaaVBWRWzB6Qa1v79+xeBdtMLIAAAQJO5aMIee+xRXD72H//4R3HBghRo99lnn/jIRz7SMC0EAICteQWwJIXXdKEEAADIYgAYAAA0JcIsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQrSYRZseNGxc9evSIdu3aRZ8+feKFF17Y4v4rVqyICy+8MHbbbbdo27Zt7LvvvvH44483WnsBAGgaWpe6AZMnT46hQ4fG+PHjiyA7duzY6N+/f7zyyiux6667brb/unXr4oQTTihue+ihh6Jbt27x17/+NXbccceStB8AgGYcZseMGRNDhgyJwYMHF+sp1D722GMxYcKEuPzyyzfbP21/66234vnnn4/tttuu2JZ6dQEAaH5KWmaQellnz54d/fr1+1eDWrYs1mfOnFntMY8++mj07du3KDPo3LlzHHzwwXH99dfH+vXrq91/7dq1UVZWVmUBAGDbUNIwu3z58iKEplC6sbS+ePHiao957bXXivKCdFyqk73qqqti9OjRcd1111W7/6hRo6Jjx46VS/fu3RvksQAA0EwHgNXFhg0binrZ22+/PQ4//PA444wz4oorrijKE6ozbNiwWLlyZeWycOHCRm8zAADbYM1sp06dolWrVrFkyZIq29N6ly5dqj0mzWCQamXTcRUOOOCAoic3lS20adOmyv5ptoO0AACw7Slpz2wKnql3dfr06VV6XtN6qoutztFHHx3z5s0r9qvw6quvFiF30yALAMC2reRlBmlarjvuuCPuuuuu+NOf/hRf+9rXYs2aNZWzGwwcOLAoFaiQbk+zGVx88cVFiE0zH6QBYGlAGAAAzUvJp+ZKNa/Lli2L4cOHF6UCvXr1iqlTp1YOCluwYEExw0GFNIBr2rRpcckll8Shhx5azDObgu1ll11WwkcBAECzDLPJRRddVCzVmTFjxmbbUgnCr3/960ZoGQAATVnJywwAAKC+hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACy1STC7Lhx46JHjx7Rrl276NOnT7zwwgu1Om7SpEnRokWLOPXUUxu8jQAAND0lD7OTJ0+OoUOHxogRI+LFF1+Mnj17Rv/+/WPp0qVbPO7111+Pb33rW/GpT32q0doKAEDTUvIwO2bMmBgyZEgMHjw4DjzwwBg/fnxsv/32MWHChBqPWb9+fZx99tkxcuTI2GuvvRq1vQAANB0lDbPr1q2L2bNnR79+/f7VoJYti/WZM2fWeNw111wTu+66a5x77rmN1FIAAJqi1qW88+XLlxe9rJ07d66yPa3PnTu32mOee+65+PGPfxxz5syp1X2sXbu2WCqUlZV9wFYDANBUlLzMoC5WrVoV55xzTtxxxx3RqVOnWh0zatSo6NixY+XSvXv3Bm8nAADNoGc2BdJWrVrFkiVLqmxP6126dNls/7/85S/FwK8BAwZUbtuwYUPxtXXr1vHKK6/Exz72sSrHDBs2rBhgtnHPrEALALBtKGmYbdOmTRx++OExffr0yum1UjhN6xdddNFm+++///7x+9//vsq2K6+8suixvfnmm6sNqW3bti0WAAC2PSUNs0nqNR00aFD07t07jjjiiBg7dmysWbOmmN0gGThwYHTr1q0oF0jz0B588MFVjt9xxx2Lr5tuBwBg21fyMHvGGWfEsmXLYvjw4bF48eLo1atXTJ06tXJQ2IIFC4oZDgAAoMmF2SSVFFRXVpDMmDFji8dOnDixgVoFAEBTp8sTAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANkSZgEAyJYwCwBAtoRZAACyJcwCAJAtYRYAgGwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkq0mE2XHjxkWPHj2iXbt20adPn3jhhRdq3PeOO+6IT33qU/GRj3ykWPr167fF/QEA2HaVPMxOnjw5hg4dGiNGjIgXX3wxevbsGf3794+lS5dWu/+MGTPizDPPjKeffjpmzpwZ3bt3j8985jOxaNGiRm87AADNPMyOGTMmhgwZEoMHD44DDzwwxo8fH9tvv31MmDCh2v3vvffeuOCCC6JXr16x//77x49+9KPYsGFDTJ8+vdHbDgBAMw6z69ati9mzZxelApUNatmyWE+9rrXx9ttvx3vvvRc77bRTA7YUAICmqHUp73z58uWxfv366Ny5c5XtaX3u3Lm1Osdll10WXbt2rRKIN7Z27dpiqVBWVvYBWw0AQFNR8jKDD+J//ud/YtKkSfHII48Ug8eqM2rUqOjYsWPlkmpsAQDYNpQ0zHbq1ClatWoVS5YsqbI9rXfp0mWLx954441FmP3FL34Rhx56aI37DRs2LFauXFm5LFy4cKu1HwCAZhxm27RpE4cffniVwVsVg7n69u1b43Hf+9734tprr42pU6dG7969t3gfbdu2jQ4dOlRZAADYNpS0ZjZJ03INGjSoCKVHHHFEjB07NtasWVPMbpAMHDgwunXrVpQLJDfccEMMHz487rvvvmJu2sWLFxfbd9hhh2IBAKD5KHmYPeOMM2LZsmVFQE3BNE25lXpcKwaFLViwoJjhoMJtt91WzILwhS98ocp50jy1V199daO3HwCAZhxmk4suuqhYarpIwsZef/31RmoVAABNXdazGQAA0LwJswAAZEuYBQAgW8IsAADZEmYBAMiWMAsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAANlqXeoGAAB1c+mMoaVuAmzme8eOiVLQMwsAQLaEWQAAsiXMAgCQLWEWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbTSLMjhs3Lnr06BHt2rWLPn36xAsvvLDF/R988MHYf//9i/0POeSQePzxxxutrQAANB0lD7OTJ0+OoUOHxogRI+LFF1+Mnj17Rv/+/WPp0qXV7v/888/HmWeeGeeee2689NJLceqppxbLyy+/3OhtBwCgmYfZMWPGxJAhQ2Lw4MFx4IEHxvjx42P77bePCRMmVLv/zTffHJ/97Gfj29/+dhxwwAFx7bXXxsc//vG45ZZbGr3tAACUVutS3vm6deti9uzZMWzYsMptLVu2jH79+sXMmTOrPSZtTz25G0s9uVOmTKl2/7Vr1xZLhZUrVxZfy8rKYmt6b+2arXo++KC29s94Q1n97rpSNwGye+2sXfOvv2uwLb52Ks5VXl7etMPs8uXLY/369dG5c+cq29P63Llzqz1m8eLF1e6ftldn1KhRMXLkyM22d+/e/QO1HZq6h75X6hZApq66v9QtgCz9IG7d6udctWpVdOzYsemG2caQen037sndsGFDvPXWW7HzzjtHixYtSto2qn8nlt5oLFy4MDp06FDq5kAWvG6gfrx2mq7UI5uCbNeuXd9335KG2U6dOkWrVq1iyZIlVban9S5dulR7TNpel/3btm1bLBvbcccdP3DbaVjpl4pfLFA3XjdQP147TdP79cg2iQFgbdq0icMPPzymT59epec0rfft27faY9L2jfdPnnjiiRr3BwBg21XyMoNUAjBo0KDo3bt3HHHEETF27NhYs2ZNMbtBMnDgwOjWrVtR+5pcfPHFccwxx8To0aPj5JNPjkmTJsWsWbPi9ttvL/EjAQCg2YXZM844I5YtWxbDhw8vBnH16tUrpk6dWjnIa8GCBcUMBxWOOuqouO++++LKK6+M73znO7HPPvsUMxkcfPDBJXwUbC2pJCTNObxpaQhQM68bqB+vnW1Di/LazHkAAABNUMkvmgAAAPUlzAIAkC1hFgCAbAmzAABkS5il0T388MPxmc98pvIqbHPmzKnVcQ8++GDsv//+0a5duzjkkEPi8ccfb/C2QlMxbty46NGjR/Hz36dPn3jhhRe2uL/XC0Q888wzMWDAgOIqUunvTZr96P3MmDEjPv7xjxczHOy9994xceLERmkr9SfM0ujSPMKf/OQn44Ybbqj1Mc8//3yceeaZce6558ZLL70Up556arG8/PLLDdpWaAomT55czMmdphB68cUXo2fPntG/f/9YunRptft7vcC//t6k10t6M1gb8+fPL+awP+6444qOlm9+85tx3nnnxbRp0xq8rdSfqbkomddffz323HPP4o9tml/4/eYjTr+Ufv7zn1duO/LII4vjxo8f3withdJJPbGf+MQn4pZbbqm8UmK6nvzXv/71uPzyyzfb3+sFNpd6Zh955JHijV1NLrvssnjssceqvPH74he/GCtWrCjmwKdp0jNLFmbOnBn9+vWrsi31TKXtsC1bt25dzJ49u8rPf7qQTFqv6eff6wXqx2snT8IsWUhXh6u4KlyFtJ62w7Zs+fLlsX79+jr9/Hu9QP3U9NopKyuLd955p2TtYsuEWRrUvffeGzvssEPl8uyzz5a6SQDANqR1qRvAtu2UU04p6v0qdOvWrV7n6dKlSyxZsqTKtrSetsO2rFOnTtGqVas6/fx7vUD91PTa6dChQ7Rv375k7WLL9MzSoD784Q8XU5tULPX9ZdC3b9+YPn16lW1PPPFEsR22ZW3atInDDz+8ys9/GgCW1mv6+fd6gfrx2smTnlka3VtvvRULFiyIN954o1h/5ZVXKt8RV/QcDRw4sOjFHTVqVLF+8cUXxzHHHBOjR48upk2ZNGlSzJo1K26//fYSPhJoHGlarkGDBkXv3r3jiCOOiLFjxxazFQwePLi43esFqrd69eqYN29elam30pRbO+20U+y+++4xbNiwWLRoUdx9993F7eeff34xa8ill14aX/nKV+Kpp56KBx54oJjhgCYsTc0FjenOO+9M08FttowYMaJyn2OOOaZ80KBBVY574IEHyvfdd9/yNm3alB900EHljz32WAlaD6Xxwx/+sHz33Xcvfv6POOKI8l//+teVt3m9QPWefvrpav/eVLxe0tf0+tn0mF69ehWvnb322qv4m0XTZp5ZAACypWYWAIBsCbMAAGRLmAUAIFvCLAAA2RJmAQDIljALAEC2hFkAALIlzAIAkC1hFgCAbAmzAABkS5gFACBbwiwAAJGr/wfGRnOuQVPfPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=df['new_sentiment'], palette=\"muted\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Distribution of data\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00f741c-d1d7-43ad-8095-cb888de25f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)  # Remove mentions and hashtags\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "df['clean_tweet'] = df['tweet'].astype(str).apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0837516-a791-4ca4-bd5b-7c167684ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kgadg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kgadg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kgadg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  when modi promised “minimum government maximum...   \n",
      "1  talk all the nonsense and continue all the dra...   \n",
      "2  what did just say vote for modi  welcome bjp t...   \n",
      "3  asking his supporters prefix chowkidar their n...   \n",
      "4  answer who among these the most powerful world...   \n",
      "\n",
      "                                     processed_tweet  new_sentiment  \n",
      "0  modi promised minimum government maximum gover...           -1.0  \n",
      "1             talk nonsense continue drama vote modi            0.0  \n",
      "2  say vote modi welcome bjp told rahul main camp...            1.0  \n",
      "3  asking supporter prefix chowkidar name modi gr...            1.0  \n",
      "4  answer among powerful world leader today trump...            1.0  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['processed_tweet'] = df['clean_tweet'].apply(preprocess_text)\n",
    "\n",
    "# Display processed data\n",
    "print(df[['tweet', 'processed_tweet', 'new_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f24427-8aa5-4c64-8b53-af2d8b973ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"processed_twitter_data.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34fc72c8-f55c-4340-9d00-b54b3e64ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (3305372, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Consider top 5000 words\n",
    "\n",
    "# Transform text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['processed_tweet'])\n",
    "\n",
    "print(\"TF-IDF feature shape:\", X_tfidf.shape)  # Check dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85140570-5cea-4290-83dd-8fd1b70721f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.3 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (4.3.3)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493c1c27-342d-4d3a-8ab4-e16c41e24d35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert tweets into tokenized word lists\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [tweet\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_tweet\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\gensim\\matutils.py:1034\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\gensim\\_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Convert tweets into tokenized word lists\n",
    "sentences = [tweet.split() for tweet in df['processed_tweet']]\n",
    "\n",
    "# Train Word2Vec Model\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate word vectors for each tweet\n",
    "def get_w2v_vector(text):\n",
    "    words = text.split()\n",
    "    vector = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    return sum(vector) / len(vector) if vector else [0] * 100  # Handle empty tweets\n",
    "\n",
    "df['w2v_features'] = df['processed_tweet'].apply(get_w2v_vector)\n",
    "\n",
    "print(\"Word2Vec feature extraction done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93e1ea49-3aad-4213-a449-6c9f9c6ac2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature matrix (X) and target variable (y)\n",
    "X = X_tfidf  # Or use Word2Vec features\n",
    "y = df['new_sentiment']\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing sets!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d4dbc-6930-4a06-9574-82f891ed3033",
   "metadata": {},
   "source": [
    " Step 6: Model Selection & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d947b11-9a63-443b-b1f6-65555bc470a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7591105396513255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# (a) Train Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71918f85-32f2-4cba-b5aa-ae2c1362cf72",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      4\u001b[0m model_rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model_rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m model_rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred_rf))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    190\u001b[0m         X,\n\u001b[0;32m    191\u001b[0m         y,\n\u001b[0;32m    192\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    193\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# (b) Train Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f505647-b975-4643-8cc6-b75233294a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/124.9 MB 1.7 MB/s eta 0:01:15\n",
      "   ---------------------------------------- 1.0/124.9 MB 1.9 MB/s eta 0:01:07\n",
      "   ---------------------------------------- 1.3/124.9 MB 1.9 MB/s eta 0:01:05\n",
      "    --------------------------------------- 1.8/124.9 MB 2.1 MB/s eta 0:00:59\n",
      "    --------------------------------------- 2.6/124.9 MB 2.3 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 3.1/124.9 MB 2.4 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 3.9/124.9 MB 2.5 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 4.7/124.9 MB 2.7 MB/s eta 0:00:46\n",
      "   - -------------------------------------- 5.2/124.9 MB 2.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 5.8/124.9 MB 2.7 MB/s eta 0:00:45\n",
      "   -- ------------------------------------- 6.6/124.9 MB 2.7 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 6.8/124.9 MB 2.7 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 7.3/124.9 MB 2.6 MB/s eta 0:00:45\n",
      "   -- ------------------------------------- 7.6/124.9 MB 2.6 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 7.9/124.9 MB 2.5 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 8.1/124.9 MB 2.5 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 8.4/124.9 MB 2.4 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 8.9/124.9 MB 2.3 MB/s eta 0:00:51\n",
      "   -- ------------------------------------- 9.2/124.9 MB 2.3 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 9.7/124.9 MB 2.3 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 10.2/124.9 MB 2.3 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 10.7/124.9 MB 2.3 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 11.3/124.9 MB 2.3 MB/s eta 0:00:50\n",
      "   --- ------------------------------------ 11.8/124.9 MB 2.3 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 12.6/124.9 MB 2.4 MB/s eta 0:00:48\n",
      "   ---- ----------------------------------- 13.4/124.9 MB 2.4 MB/s eta 0:00:47\n",
      "   ---- ----------------------------------- 14.2/124.9 MB 2.5 MB/s eta 0:00:45\n",
      "   ---- ----------------------------------- 15.2/124.9 MB 2.5 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 16.0/124.9 MB 2.6 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 17.0/124.9 MB 2.7 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 17.8/124.9 MB 2.7 MB/s eta 0:00:40\n",
      "   ------ --------------------------------- 19.1/124.9 MB 2.8 MB/s eta 0:00:38\n",
      "   ------ --------------------------------- 20.2/124.9 MB 2.9 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 21.0/124.9 MB 2.9 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 21.8/124.9 MB 2.9 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 22.3/124.9 MB 2.9 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 22.5/124.9 MB 2.9 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 22.8/124.9 MB 2.9 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 23.1/124.9 MB 2.8 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 23.6/124.9 MB 2.8 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 23.9/124.9 MB 2.8 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 24.1/124.9 MB 2.7 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 24.4/124.9 MB 2.7 MB/s eta 0:00:38\n",
      "   ------- -------------------------------- 24.6/124.9 MB 2.7 MB/s eta 0:00:38\n",
      "   ------- -------------------------------- 24.9/124.9 MB 2.6 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 25.4/124.9 MB 2.6 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 25.7/124.9 MB 2.6 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 26.2/124.9 MB 2.6 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 26.5/124.9 MB 2.6 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 27.0/124.9 MB 2.5 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 27.3/124.9 MB 2.5 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 27.8/124.9 MB 2.5 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 28.0/124.9 MB 2.5 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 28.6/124.9 MB 2.5 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 29.4/124.9 MB 2.5 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 29.9/124.9 MB 2.5 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 30.7/124.9 MB 2.5 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 31.2/124.9 MB 2.6 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 32.0/124.9 MB 2.6 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 32.5/124.9 MB 2.6 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 32.8/124.9 MB 2.6 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 33.0/124.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 33.3/124.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 33.6/124.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 34.1/124.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 34.6/124.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 34.6/124.9 MB 2.5 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 2.4 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 2.4 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 2.4 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 2.4 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 2.3 MB/s eta 0:00:39\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 2.3 MB/s eta 0:00:39\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 2.3 MB/s eta 0:00:39\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 36.4/124.9 MB 2.2 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 36.7/124.9 MB 2.2 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 36.7/124.9 MB 2.2 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 36.7/124.9 MB 2.2 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 37.0/124.9 MB 2.2 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 37.0/124.9 MB 2.2 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 37.2/124.9 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 37.2/124.9 MB 2.1 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 37.5/124.9 MB 2.1 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 37.5/124.9 MB 2.1 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 37.7/124.9 MB 2.0 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 38.0/124.9 MB 2.0 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 38.0/124.9 MB 2.0 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 38.0/124.9 MB 2.0 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 38.3/124.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 38.3/124.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 38.3/124.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.5/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 38.8/124.9 MB 1.7 MB/s eta 0:00:50\n",
      "   ------------ --------------------------- 39.1/124.9 MB 1.6 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 39.1/124.9 MB 1.6 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 39.1/124.9 MB 1.6 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 39.1/124.9 MB 1.6 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 39.3/124.9 MB 1.6 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 39.6/124.9 MB 1.5 MB/s eta 0:00:56\n",
      "   ------------ --------------------------- 39.8/124.9 MB 1.5 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 40.4/124.9 MB 1.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 40.9/124.9 MB 1.6 MB/s eta 0:00:54\n",
      "   ------------- -------------------------- 41.2/124.9 MB 1.6 MB/s eta 0:00:54\n",
      "   ------------- -------------------------- 41.7/124.9 MB 1.6 MB/s eta 0:00:54\n",
      "   ------------- -------------------------- 42.2/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   ------------- -------------------------- 42.5/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   ------------- -------------------------- 42.7/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   ------------- -------------------------- 43.0/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   ------------- -------------------------- 43.3/124.9 MB 1.6 MB/s eta 0:00:52\n",
      "   ------------- -------------------------- 43.5/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 43.8/124.9 MB 1.6 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 44.0/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 44.0/124.9 MB 1.6 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 44.3/124.9 MB 1.5 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 44.6/124.9 MB 1.5 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 44.8/124.9 MB 1.5 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 45.1/124.9 MB 1.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 45.6/124.9 MB 1.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 46.1/124.9 MB 1.5 MB/s eta 0:00:51\n",
      "   -------------- ------------------------- 46.7/124.9 MB 1.6 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 47.2/124.9 MB 1.6 MB/s eta 0:00:50\n",
      "   --------------- ------------------------ 47.7/124.9 MB 1.6 MB/s eta 0:00:50\n",
      "   --------------- ------------------------ 48.5/124.9 MB 1.6 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 49.0/124.9 MB 1.6 MB/s eta 0:00:49\n",
      "   --------------- ------------------------ 49.5/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.1/124.9 MB 1.6 MB/s eta 0:00:48\n",
      "   ---------------- ----------------------- 50.9/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 52.7/124.9 MB 1.6 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 53.2/124.9 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------------- ---------------------- 54.0/124.9 MB 1.6 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 54.8/124.9 MB 1.6 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 1.6 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 56.1/124.9 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 56.9/124.9 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 57.4/124.9 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 58.2/124.9 MB 1.7 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 59.0/124.9 MB 1.7 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 59.8/124.9 MB 1.7 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 60.8/124.9 MB 1.7 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 61.9/124.9 MB 1.7 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 62.7/124.9 MB 1.7 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 63.4/124.9 MB 1.7 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 64.2/124.9 MB 1.7 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 65.3/124.9 MB 1.7 MB/s eta 0:00:35\n",
      "   --------------------- ------------------ 66.1/124.9 MB 1.7 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 66.8/124.9 MB 1.7 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 67.9/124.9 MB 1.7 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 68.9/124.9 MB 1.7 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 69.7/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 70.5/124.9 MB 1.7 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 71.3/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.1/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 72.9/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 73.4/124.9 MB 1.7 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 73.9/124.9 MB 1.7 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 74.2/124.9 MB 1.7 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 74.7/124.9 MB 1.7 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 75.0/124.9 MB 1.7 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 75.5/124.9 MB 1.7 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 76.0/124.9 MB 1.7 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 76.5/124.9 MB 1.7 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 76.8/124.9 MB 1.7 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 77.1/124.9 MB 1.7 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 77.6/124.9 MB 1.7 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 77.9/124.9 MB 1.7 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 78.4/124.9 MB 1.7 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 78.9/124.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 79.4/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 79.7/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 80.0/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 80.5/124.9 MB 1.8 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 81.0/124.9 MB 1.7 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 81.3/124.9 MB 1.7 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 81.5/124.9 MB 1.7 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 81.8/124.9 MB 1.7 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 82.1/124.9 MB 1.7 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 82.6/124.9 MB 1.7 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 82.8/124.9 MB 1.7 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 83.1/124.9 MB 1.7 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 83.6/124.9 MB 1.7 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 84.1/124.9 MB 1.7 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 84.4/124.9 MB 1.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 84.7/124.9 MB 1.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 84.9/124.9 MB 1.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 85.5/124.9 MB 1.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 85.7/124.9 MB 1.7 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 86.0/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 86.2/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 86.5/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 86.5/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 86.5/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 86.8/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 87.0/124.9 MB 1.7 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 87.3/124.9 MB 1.7 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 87.6/124.9 MB 1.7 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 87.6/124.9 MB 1.7 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 87.8/124.9 MB 1.7 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 1.7 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 1.7 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 88.6/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 88.6/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 88.9/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.1/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 1.8 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 1.8 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 1.8 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 1.8 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 1.8 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 1.8 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.7/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.7/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.7/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 1.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 1.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 1.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 1.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 90.4/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 91.0/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 91.0/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 91.0/124.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 91.2/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 91.2/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 91.5/124.9 MB 1.7 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 91.8/124.9 MB 1.6 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 92.0/124.9 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 92.5/124.9 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 92.8/124.9 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 93.6/124.9 MB 1.7 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 93.8/124.9 MB 1.7 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 94.4/124.9 MB 1.7 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 94.6/124.9 MB 1.7 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 94.9/124.9 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.2/124.9 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.2/124.9 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.4/124.9 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.4/124.9 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.7/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.7/124.9 MB 1.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 95.9/124.9 MB 1.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 96.2/124.9 MB 1.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 96.5/124.9 MB 1.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 96.7/124.9 MB 1.6 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 97.0/124.9 MB 1.5 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 97.3/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 97.8/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.0/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 98.6/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.1/124.9 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 99.9/124.9 MB 1.5 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 100.4/124.9 MB 1.5 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 100.9/124.9 MB 1.5 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 101.4/124.9 MB 1.5 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 102.0/124.9 MB 1.5 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 102.0/124.9 MB 1.5 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 102.0/124.9 MB 1.5 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 102.2/124.9 MB 1.4 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 102.5/124.9 MB 1.4 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 102.8/124.9 MB 1.4 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 103.0/124.9 MB 1.3 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 103.3/124.9 MB 1.3 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 103.8/124.9 MB 1.3 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 104.3/124.9 MB 1.3 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 104.9/124.9 MB 1.3 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.4/124.9 MB 1.3 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 105.9/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 106.4/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 107.0/124.9 MB 1.3 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 107.7/124.9 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 108.3/124.9 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 109.1/124.9 MB 1.2 MB/s eta 0:00:14\n",
      "   ----------------------------------- ---- 109.6/124.9 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 109.8/124.9 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 110.1/124.9 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 110.4/124.9 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 110.9/124.9 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 111.1/124.9 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 111.7/124.9 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 112.2/124.9 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 112.7/124.9 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 113.0/124.9 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 113.5/124.9 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 114.0/124.9 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 114.6/124.9 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 115.3/124.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 116.1/124.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 116.9/124.9 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 117.7/124.9 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 118.5/124.9 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 119.3/124.9 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 120.1/124.9 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 120.8/124.9 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 121.4/124.9 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  122.2/124.9 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  122.9/124.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  123.5/124.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  124.3/124.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 124.9/124.9 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "786a14b4-17a6-467d-bf13-03fd08f5ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.733225428279696\n"
     ]
    }
   ],
   "source": [
    "# (c) Train XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Shift labels from [-1, 0, 1] to [0, 1, 2]\n",
    "y_train_shifted = y_train + 1\n",
    "y_test_shifted = y_test + 1\n",
    "\n",
    "# Train XGBoost Model\n",
    "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model_xgb.fit(X_train, y_train_shifted)\n",
    "\n",
    "# Predict & shift back the labels\n",
    "y_pred_xgb = model_xgb.predict(X_test) - 1\n",
    "\n",
    "# Evaluate\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e32be4bb-a1d1-43c9-88da-9339b92ec1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m    7/41318\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m406:29:47\u001b[0m 35s/step - accuracy: 0.4711 - loss: 0.9894"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 16\u001b[0m\n\u001b[0;32m      8\u001b[0m model_lstm \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      9\u001b[0m     Embedding(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m     10\u001b[0m     LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     11\u001b[0m     LSTM(\u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m     12\u001b[0m     Dense(\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 3 classes: Positive, Negative, Neutral\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ])\n\u001b[0;32m     15\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_shifted, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test_shifted))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 7: Train Deep Learning Models\n",
    "# Try LSTM (Long Short-Term Memory) and BERT for improved accuracy.\n",
    "# (a) Train LSTM Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(3, activation='softmax')  # 3 classes: Positive, Negative, Neutral\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train_shifted, epochs=5, batch_size=64, validation_data=(X_test, y_test_shifted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d54be9f-21e6-4f86-8226-4ae548854136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.8/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.6/10.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/10.0 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/10.0 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/10.0 MB 1.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 999.7 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 999.7 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 999.7 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 999.7 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 810.3 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.1/10.0 MB 342.4 kB/s eta 0:00:20\n",
      "   ------------ --------------------------- 3.1/10.0 MB 342.4 kB/s eta 0:00:20\n",
      "   ------------ --------------------------- 3.1/10.0 MB 342.4 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 3.4/10.0 MB 342.4 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 3.4/10.0 MB 342.4 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 3.4/10.0 MB 342.4 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 3.7/10.0 MB 354.1 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 3.9/10.0 MB 369.3 kB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 386.6 kB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 386.6 kB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 397.7 kB/s eta 0:00:14\n",
      "   ------------------ --------------------- 4.7/10.0 MB 411.0 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 5.0/10.0 MB 426.5 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 5.2/10.0 MB 444.0 kB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 478.7 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 6.0/10.0 MB 496.1 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 6.6/10.0 MB 530.5 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 563.6 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 7.6/10.0 MB 597.7 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.1/10.0 MB 628.3 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.4/10.0 MB 643.7 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 653.1 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 657.6 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 657.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.0 MB 660.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.0 MB 660.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.0 MB 660.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 9.4/10.0 MB 649.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 649.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 651.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 651.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 647.2 kB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   -------- ------------------------------- 0.5/2.4 MB 54.3 kB/s eta 0:00:35\n",
      "   ------------- -------------------------- 0.8/2.4 MB 45.2 kB/s eta 0:00:36\n",
      "   ------------- -------------------------- 0.8/2.4 MB 45.2 kB/s eta 0:00:36\n",
      "   ------------- -------------------------- 0.8/2.4 MB 45.2 kB/s eta 0:00:36\n",
      "   ------------- -------------------------- 0.8/2.4 MB 45.2 kB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 62.8 kB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 62.8 kB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 62.8 kB/s eta 0:00:22\n",
      "   --------------------- ------------------ 1.3/2.4 MB 80.4 kB/s eta 0:00:14\n",
      "   -------------------------- ------------- 1.6/2.4 MB 97.5 kB/s eta 0:00:09\n",
      "   -------------------------- ------------- 1.6/2.4 MB 97.5 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 1.8/2.4 MB 114.4 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 131.1 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 131.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------- 2.4/2.4 MB 147.8 kB/s eta 0:00:00\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.1 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2160e1ce-9981-45e6-b38e-c0608cae0cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-kerasNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kgadg\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 996.8 kB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3afcf866-f3bd-49ad-b0cc-513d801927bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kgadg\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m model_bert \u001b[38;5;241m=\u001b[39m TFBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m X_train_tokens \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;28mlist\u001b[39m(X_train), truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m X_test_tokens \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;28mlist\u001b[39m(X_test), truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m model_bert\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2877\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2876\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2877\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2879\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2937\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   2934\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[1;32m-> 2937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2939\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2940\u001b[0m     )\n\u001b[0;32m   2942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[0;32m   2943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2945\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2946\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "# (b) Train Transformer Model (BERT)\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "X_train_tokens = tokenizer(list(X_train), truncation=True, padding=True, max_length=512, return_tensors=\"tf\")\n",
    "X_test_tokens = tokenizer(list(X_test), truncation=True, padding=True, max_length=512, return_tensors=\"tf\")\n",
    "\n",
    "model_bert.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_bert.fit(X_train_tokens, y_train, epochs=3, batch_size=32, validation_data=(X_test_tokens, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b97b266d-3150-4341-9fcc-487954093601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kgadg\\anaconda3\\envs\\Deep_Learning\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:51:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.7595779601406799\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', model_lr),\n",
    "    ('xgb', model_xgb)\n",
    "], voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "print(\"Ensemble Model Accuracy:\", accuracy_score(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b614918e-182b-4eeb-9124-9f056ff03431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.75      0.78      0.77    321299\n",
      "         0.0       0.76      0.75      0.76    323288\n",
      "         1.0       0.86      0.49      0.62     16488\n",
      "\n",
      "    accuracy                           0.76    661075\n",
      "   macro avg       0.79      0.67      0.72    661075\n",
      "weighted avg       0.76      0.76      0.76    661075\n",
      "\n",
      "Confusion Matrix:\n",
      " [[252109  68315    875]\n",
      " [ 80838 241980    470]\n",
      " [  2300   6139   8049]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_voting))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fbba0-789e-4987-ae3d-5dd6914d4d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
